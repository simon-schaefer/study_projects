{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "verified\n",
      "analysis time:  0.477675199508667  seconds\n"
     ]
    }
   ],
   "source": [
    "import analyzer\n",
    "import time\n",
    "import pandas as pd\n",
    "%run analyzer.py mnist_nets/mnist_relu_3_10.txt mnist_images/img0.txt 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class interval_object:\n",
    "    \"\"\"Interval object to save the results of a box pass through the network\n",
    "    Logits are saved in logit_intervals dictionary (they are needed to compute slope and intercept in full\n",
    "    zonotope analysis)\n",
    "    ReLU of logits are saved in intervals dictionary\n",
    "    For the naming convention checkout the naming file.\"\"\"\n",
    "    def __init__(self, xl, xu):\n",
    "        self.xl_in = xl\n",
    "        self.xu_in = xu\n",
    "        self.numlayer = 0\n",
    "        self.intervals = {\n",
    "            'xl_0': xl,\n",
    "            'xu_0': xu\n",
    "        }\n",
    "        self.logit_intervals = {}\n",
    "        self.fitted = False\n",
    "\n",
    "    def set_logit_bounds(self, layer_k, hl, hu):\n",
    "        assert self.numlayer > 0\n",
    "        assert (layer_k < self.numlayer) and (layer_k >= 0)\n",
    "        self.logit_intervals['hl_' + str(layer_k)] = hl\n",
    "        self.logit_intervals['hu_' + str(layer_k)] = hu\n",
    "\n",
    "    def set_bounds(self, layer_k, xl, xu):\n",
    "        assert self.numlayer > 0\n",
    "        assert (layer_k <= self.numlayer) and (layer_k >= 0)\n",
    "        if not self.fitted:\n",
    "            self.intervals['xl_' + str(layer_k)] = xl\n",
    "            self.intervals['xu_' + str(layer_k)] = xu\n",
    "        else:\n",
    "            #only allow to tighten bounds\n",
    "            for i in range(len(xl)):\n",
    "                if xl[i] > self.intervals['xl_' + str(layer_k)][i]:\n",
    "                    self.intervals['xl_' + str(layer_k)][i] = xl[i]\n",
    "                if xu[i] < self.intervals['xu_' + str(layer_k)][i]:\n",
    "                    self.intervals['xu_' + str(layer_k)][i] = xu[i]\n",
    "\n",
    "    def get_bounds(self, layer_k):\n",
    "        assert self.fitted\n",
    "        assert(layer_k <= self.numlayer) and (layer_k >= 0)\n",
    "        return self.intervals['xl_'+str(layer_k)], self.intervals['xu_'+str(layer_k)]\n",
    "\n",
    "    def get_logit_bounds(self, layer_k):\n",
    "        assert self.fitted\n",
    "        assert(layer_k < self.numlayer) and (layer_k >= 0)\n",
    "        return self.logit_intervals['hl_'+str(layer_k)], self.logit_intervals['hu_'+str(layer_k)]\n",
    "\n",
    "    def get_input_bounds(self):\n",
    "        # equivalent to get_bounds(layer_k = 0)\n",
    "        return self.xl_in, self.xu_in\n",
    "\n",
    "    def fit(self, nn, layer_k = 0):\n",
    "        '''Fits with box from layer_k as input'''\n",
    "        num_layer = nn.numlayer\n",
    "        self.numlayer = num_layer\n",
    "        xl = self.xl_in\n",
    "        xu = self.xu_in\n",
    "        num_pixels = len(xl)\n",
    "        assert (num_pixels == len(xu))\n",
    "        assert layer_k <= num_layer\n",
    "\n",
    "        # Box pass through network and save intervals in self.intervals dictionary\n",
    "        for k in range(layer_k, num_layer):\n",
    "            layer_type = nn.layertypes[k]\n",
    "            weights = np.array(nn.weights[k])\n",
    "            biases = np.array(nn.biases[k])\n",
    "            xl_k, xu_k = self.intervals['xl_'+str(k)], self.intervals['xu_'+str(k)]\n",
    "\n",
    "            # Peform affine transform to get logits bounds hl_k, hu_k for kth layer\n",
    "            hl_k, hu_k = analyze_layer_box(weights, biases, 'Affine', xl_k, xu_k)\n",
    "            self.set_logit_bounds(k, hl_k, hu_k)\n",
    "\n",
    "            # Perform relu operation to get new interval bounds xl_new, xu_new\n",
    "            if layer_type == 'ReLU':\n",
    "                xl_new = deepcopy(hl_k)\n",
    "                xu_new = deepcopy(hu_k)\n",
    "                xl_new[xl_new < 0] = 0\n",
    "                xu_new[xu_new < 0] = 0\n",
    "                self.set_bounds(k+1, xl_new, xu_new)\n",
    "\n",
    "        self.fitted = True\n",
    "        return xl_new, xu_new\n",
    "\n",
    "    def print(self):\n",
    "        # print('====== Input ======')\n",
    "        # print_lower_upper(xl, xu)\n",
    "\n",
    "        for k in range(self.numlayer):\n",
    "            print('===== Logits bounds layer ' + str(k) + ' ======')\n",
    "            print_lower_upper(*self.get_logit_bounds(k))\n",
    "\n",
    "            print('===== Interval bounds layer ' + str(k + 1) + ' =====')\n",
    "            print_lower_upper(*self.get_bounds(k + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_split(model, layer_k, dim_m, h_lb, h_ub, x_lb, x_ub, h_km):\n",
    "    assert h_lb <= h_ub\n",
    "    assert x_lb <= x_ub\n",
    "    assert x_lb >= 0\n",
    "    \n",
    "    x_km = model.addVar(vtype=GRB.CONTINUOUS, name=\"x_\"+str(layer_k)+'_' +str(dim_m))\n",
    "    \n",
    "    if h_ub < 0: #Zero case\n",
    "        C0 = model.addLConstr(x_km == 0)\n",
    "        constraints = [C0]\n",
    "        flag = 0\n",
    "\n",
    "    elif h_lb >= 0:\n",
    "        C0 = model.addLConstr(x_km == h_km)\n",
    "        constraints = [C0]\n",
    "        flag = 1\n",
    "\n",
    "    else:\n",
    "        assert x_lb >= 0\n",
    "        assert x_ub >= 0\n",
    "        assert x_ub <= h_ub\n",
    "    \n",
    "        slope = x_ub / (x_ub - h_lb)\n",
    "        intercept = -slope * h_lb\n",
    "        assert intercept > 0\n",
    "        \n",
    "        C0 = model.addLConstr(x_km >= 0)\n",
    "        C1 = model.addLConstr(x_km >= h_km)\n",
    "        C2 = model.addLConstr(x_km <= slope * h_km + intercept)\n",
    "        constraints = [C0,C1,C2]\n",
    "        flag = 2\n",
    "        \n",
    "    return x_km, flag, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ub_convergence(x_ub, xu_old, abs_tol, rel_tol):\n",
    "    if (xu_old - x_ub < abs_tol):\n",
    "        #print('abs ub')\n",
    "        return True\n",
    "    if x_ub < 1e-5 or xu_old < 1e-5:\n",
    "        x_ub = 0\n",
    "        #print('0 ub')\n",
    "        return True\n",
    "    \n",
    "    if (xu_old - x_ub)/xu_old < rel_tol:\n",
    "        #print('rel ub')\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lb_convergence(x_lb, xl_old, abs_tol, rel_tol):\n",
    "    if x_lb == 0:\n",
    "        return True\n",
    "    if (x_lb - xl_old  < abs_tol):\n",
    "        #print('abs lb')\n",
    "        return True\n",
    "    if (x_lb - xl_old )/x_lb < rel_tol:\n",
    "        #print('rel lb')\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tighten_bounds(model, x_km, flag, xl_old, xu_old, h_lb, h_km, constraints, abs_tol = 0.005, rel_tol = 0.01):  \n",
    "    #Stable RELU case\n",
    "    if len(constraints) == 1:\n",
    "        model.reset()\n",
    "        model.setObjective(x_km, GRB.MAXIMIZE)\n",
    "        model.optimize()\n",
    "        x_ub = x_km.X\n",
    "        \n",
    "        if x_ub > 0:\n",
    "            model.reset()\n",
    "            model.setObjective(x_km, GRB.MINIMIZE)\n",
    "            model.optimize()\n",
    "            x_lb = x_km.X\n",
    "        else:\n",
    "            x_lb = 0\n",
    "        return x_lb, x_ub\n",
    "    \n",
    "    #RELU-Triangle case\n",
    "    assert len(constraints) == 3\n",
    "    model.reset()\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        model.setObjective(x_km, GRB.MAXIMIZE)\n",
    "        model.optimize()\n",
    "        x_ub = x_km.X\n",
    "        \n",
    "        if x_ub < 1e-4:\n",
    "            model.remove(constraints[0])\n",
    "            model.remove(constraints[1])\n",
    "            model.remove(constraints[2])\n",
    "            model.addLConstr(x_km == 0)\n",
    "            model.update()\n",
    "            x_ub = 0\n",
    "            return 0, 0  #In this case both lower and upper bound ==0\n",
    "        \n",
    "        else: #slope update\n",
    "            new_slope = x_ub / (x_ub - h_lb)\n",
    "            new_intercept = -new_slope * h_lb\n",
    "            assert new_intercept > 0\n",
    "            model.remove(constraints[2])\n",
    "            constraints[2] = model.addLConstr(x_km <= new_slope * h_km + new_intercept)\n",
    "            #constraints[2].setAttr('rhs', new_slope * h_km + new_intercept)\n",
    "            model.update()\n",
    "        \n",
    "        #Convergence check\n",
    "        converged = check_ub_convergence(x_ub, xu_old, abs_tol, rel_tol)\n",
    "        xu_old = x_ub\n",
    "    \n",
    "    #Find lower bound\n",
    "    model.reset()\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        model.setObjective(x_km, GRB.MINIMIZE)\n",
    "        model.optimize()\n",
    "        x_lb = x_km.X\n",
    "        \n",
    "        #Convergence check\n",
    "        converged = check_lb_convergence(x_ub, xu_old, abs_tol, rel_tol)\n",
    "        xu_old = x_ub\n",
    "        \n",
    "    return x_lb, x_ub\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_layer_l(layer_k, nn, iobj, model, varis, label): \n",
    "    '''Optimizes layer_k '''\n",
    "    # Inits\n",
    "    relu_bin = {'zero':0, 'lin':0, 'unstable':0, 'aff':0}\n",
    "    \n",
    "    # Get weights, biases & layertype from nn\n",
    "    layer_type = nn.layertypes[layer_k-1]\n",
    "    weights = np.array(nn.weights[layer_k-1])\n",
    "    biases = np.array(nn.biases[layer_k-1])\n",
    "    \n",
    "    # Input and output dimensions for the k-th layer\n",
    "    in_dim  = weights.shape[1]\n",
    "    out_dim = weights.shape[0]\n",
    "    \n",
    "    # Get interval bounds from intervall object to calculate slope and intercept\n",
    "    hl, hu = iobj.get_logit_bounds(layer_k-1)\n",
    "    xl, xu = iobj.get_bounds(layer_k)\n",
    "    assert hl.size == out_dim\n",
    "    assert xl.size == out_dim       # The x's are ReLU(h)\n",
    "    \n",
    "    for dim_m in range(out_dim):\n",
    "        ws = weights[dim_m,:]  #one row of weights\n",
    "        b  = biases[dim_m]\n",
    "\n",
    "        # Perform affine transform:  x_kn --> h_km where n iterates over input and m over output dimension\n",
    "        h_km = LinExpr(b)\n",
    "        for dim_n in range(in_dim):\n",
    "            h_km.add( ws[dim_n] * varis['x_'+str(layer_k-1)+'_'+str(dim_n)] )\n",
    "\n",
    "        # Activation\n",
    "        if layer_type == 'ReLU':\n",
    "            x_km, flag, constraints = relu_split(model, layer_k, dim_m, \n",
    "                                      h_lb=hl[dim_m], h_ub=hu[dim_m], x_lb=xl[dim_m], x_ub=xu[dim_m], \n",
    "                                      h_km=h_km)\n",
    "            if flag == 0:\n",
    "                relu_bin['zero'] +=1\n",
    "            elif flag == 1:\n",
    "                relu_bin['lin'] +=1\n",
    "            elif flag == 2:\n",
    "                relu_bin['unstable'] +=1\n",
    "        else: #Affine case\n",
    "            x_km = h_km\n",
    "            relu_bin['aff']+=1\n",
    "        \n",
    "        # Add the variable x_km to variable dictionary\n",
    "        varis['x_'+str(layer_k)+'_'+str(dim_m)] = x_km \n",
    "        \n",
    "        #TIGHTEN STEP (Only for layers btw 1 & final)\n",
    "        if xu[dim_m] > 0 and layer_k > 1:  #For first layer (1) this would just return box. \n",
    "            new_lb, new_ub = tighten_bounds(model, x_km, flag, xl[dim_m], xu[dim_m], hl[dim_m], h_km, constraints)\n",
    "            \n",
    "            assert new_lb >= xl[dim_m] - 1e-7\n",
    "            assert new_ub <= xu[dim_m] + 1e-7\n",
    "            \n",
    "            #UPDATE Layer k\n",
    "            iobj.intervals['xl_'+str(layer_k)][dim_m] = new_lb\n",
    "            iobj.intervals['xu_'+str(layer_k)][dim_m] = new_ub\n",
    "    \n",
    "    #Final layer verification\n",
    "    could_still_work = True\n",
    "    if layer_k == (nn.numlayer):\n",
    "        corr_label = varis['x_'+str(layer_k)+'_'+str(label)]\n",
    "        \n",
    "        for out_digit in range(10):\n",
    "            if varis['x_'+str(layer_k)+'_'+str(out_digit)] is not corr_label:\n",
    "                incorr_label = varis['x_' + str(layer_k) + '_' + str(out_digit)]\n",
    "                \n",
    "                model.reset()\n",
    "                model.setObjective(corr_label - incorr_label, GRB.MINIMIZE)\n",
    "                model.optimize()\n",
    "                print(corr_label)\n",
    "                print(incorr_label)\n",
    "\n",
    "                if corr_label.X - incorr_label.X <= 0:\n",
    "                    could_still_work = False\n",
    "                    break\n",
    "    \n",
    "    return relu_bin, could_still_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monitoring(): \n",
    "    ''' Monitoring remaining \"allowed\" runtime and changes in bounds. \n",
    "    Timing: Iterative timing bounds, i.e. check time consumption for last run\n",
    "            and set current timer bound to last runtime. \n",
    "    Bounds: Check \"importance\" of each neuron, i.e. activation times weight. \n",
    "    Bounds Diff: Check change of bounds to stop optimizing bounds in case it \n",
    "                 of small optimization at each iteration. \n",
    "    '''\n",
    "    MAX_TIME = 180.0 # 3min\n",
    "    MIN_CHANGE = 1e-3\n",
    "    \n",
    "    def __init__(self): \n",
    "        self.time_last = None\n",
    "        self.dt_last = self.MAX_TIME\n",
    "        self.xl_last = None\n",
    "        self.xu_last = None    \n",
    "        \n",
    "    def check(self, xl, xu):\n",
    "        proceed = True\n",
    "        dt_bounds = self.MAX_TIME\n",
    "        # Check timing bound - Do not proceed if current runtime exceed  \n",
    "        dt = self.MAX_TIME\n",
    "        if self.time_last is None: \n",
    "            pass\n",
    "        else: \n",
    "            dt = time.time() - self.time_last\n",
    "            if dt > self.dt_last: \n",
    "                proceed = False\n",
    "        dt_bounds = min(dt, self.MAX_TIME)\n",
    "        # Check lower and upper bounds. \n",
    "        discard = []\n",
    "        if self.xl_last is None or self.xu_last is None: \n",
    "            pass\n",
    "        else: \n",
    "            dxl, dxu = self.xl_last - xl, self.xu_last - xu \n",
    "            lxl, lxu = self.xl_last, self.xu_last\n",
    "            lxl[lxl == 0] = 1e-6 # avoid division error\n",
    "            cxl = np.absolute(dxl/lxl) < self.MIN_CHANGE\n",
    "            print(dxl)\n",
    "            lxu[lxu == 0] = 1e-6 # avoid division error\n",
    "            cxu = np.absolute(dxu/lxu) < self.MIN_CHANGE\n",
    "            print(cxl)\n",
    "        # Reset last parameters. \n",
    "        self.time_last = time.time()\n",
    "        self.dt_last = dt\n",
    "        self.xl_last = xl\n",
    "        self.xu_last = xu\n",
    "        return proceed, dt_bounds, discard\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggressive_analyze(netname, epsilon, specname, iobj= None):\n",
    "    verified = False\n",
    "    #Import and parse the net\n",
    "    with open(netname, 'r') as netfile:\n",
    "        netstring = netfile.read()\n",
    "    with open(specname, 'r') as specfile:\n",
    "        specstring = specfile.read()\n",
    "    nn = parse_net(netstring)\n",
    "    x0_low, x0_high = parse_spec(specstring)\n",
    "    LB_N0, UB_N0 = get_perturbed_image(x0_low,0)\n",
    "    label, _ = analyze(nn,LB_N0,UB_N0,0)\n",
    "    LB_N0, UB_N0 = get_perturbed_image(x0_low,epsilon)\n",
    "    assert(LB_N0.shape == UB_N0.shape)\n",
    "    \n",
    "    #Set up variable, expression dictionarys & relu case counter\n",
    "    varis = {}\n",
    "    relu_bins = {}\n",
    "\n",
    "    #First box pass\n",
    "    if iobj is None:\n",
    "        iobj = interval_object(LB_N0, UB_N0)\n",
    "        iobj.fit(nn)\n",
    "    if prove(*iobj.get_bounds(layer_k=nn.numlayer),label)[1]: return True, iobj, relu_bins, 0, label\n",
    "    \n",
    "    #set up gurobi model\n",
    "    model = Model(\"net\")\n",
    "    model.setParam('OutputFlag', False)\n",
    "    \n",
    "    # set up monitoring. \n",
    "    monitoring = Monitoring()\n",
    "\n",
    "    # Set up initial input variables & ranges for input image\n",
    "    for dim_n in range(len(LB_N0)):\n",
    "        x_0n  = model.addVar(LB_N0[dim_n], UB_N0[dim_n], name=\"x_0_\"+str(dim_n))\n",
    "        # Add the input variables to variable dict for later access under name x_0_n\n",
    "        varis['x_0_'+str(dim_n)] = x_0n\n",
    "        \n",
    "    # Add 1st layer to model\n",
    "    relu_bins[1], flag = optimize_layer_l(1, nn, iobj, model, varis, label)\n",
    "    \n",
    "    \n",
    "    for layer_k in range(2, nn.numlayer):\n",
    "        print('--', layer_k, '--')\n",
    "        #print_lower_upper(iobj.get_bounds(layer_k)[0][:10],iobj.get_bounds(layer_k)[1][:10])\n",
    "        #print('------------')\n",
    "        \n",
    "        relu_bins[layer_k], flag = optimize_layer_l(layer_k, nn, iobj, model, varis, label)\n",
    "        iobj.fit(nn,layer_k)\n",
    "        if prove(*iobj.get_bounds(layer_k=nn.numlayer),label)[1]: return True, iobj, relu_bins, layer_k, label\n",
    "        \n",
    "        # Iterative optimizing. \n",
    "        #model.setParam(\"TimeLimit\", monitoring.MAX_TIME)\n",
    "        for i in range(5): \n",
    "            print('----', layer_k, i, '--')\n",
    "            proceed, dt_bounds, discard = monitoring.check(xl=iobj.get_bounds(layer_k)[0],\n",
    "                                                           xu=iobj.get_bounds(layer_k)[1])\n",
    "            if not proceed: break\n",
    "            # Adapt model using monitoring results. \n",
    "            #model.setParam(\"TimeLimit\", dt_bounds)\n",
    "            # Optimization. \n",
    "            relu_bins[layer_k], flag = optimize_layer_l(layer_k, nn, iobj, model, varis, label)\n",
    "            iobj.fit(nn,layer_k)\n",
    "            if prove(*iobj.get_bounds(layer_k=nn.numlayer),label)[1]: return True, iobj, relu_bins, layer_k, label\n",
    "        \n",
    "        print('--', layer_k, ' finished--')\n",
    "        #print_lower_upper(iobj.get_bounds(layer_k)[0][:10],iobj.get_bounds(layer_k)[1][:10])\n",
    "        #print('------------')\n",
    "        #print_lower_upper(*iobj.get_bounds(nn.numlayer))\n",
    "    \n",
    "    relu_bins[nn.numlayer], flag = optimize_layer_l(nn.numlayer, nn, iobj, model, varis, label)\n",
    "    return flag, iobj, relu_bins, layer_k, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "netname = 'mnist_nets/mnist_relu_6_50.txt'\n",
    "epsilon = 0.01\n",
    "specname = 'mnist_images/img1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 2 --\n",
      "---- 2 0 --\n",
      "---- 2 1 --\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-af3bea957812>\u001b[0m in \u001b[0;36maggressive_analyze\u001b[0;34m(netname, epsilon, specname, iobj)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m#model.setParam(\"TimeLimit\", dt_bounds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mrelu_bins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_layer_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0miobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6d559395f88f>\u001b[0m in \u001b[0;36moptimize_layer_l\u001b[0;34m(layer_k, nn, iobj, model, varis, label)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mnew_lb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_ub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtighten_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_km\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_km\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mnew_lb\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mxl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_m\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mnew_ub\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mxu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_m\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "verf, iobj, relu_bins, layer_k, label = aggressive_analyze(netname, epsilon, specname)\n",
    "print(verf, label, layer_k)\n",
    "print(relu_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "netname = 'mnist_nets/mnist_relu_6_200.txt'\n",
    "epsilon = 0.01\n",
    "specname = 'mnist_images/img0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 2 --\n",
      "[0.00,\t 0.93]\n",
      "[0.00,\t 0.01]\n",
      "[0.00,\t 0.28]\n",
      "[0.00,\t 1.17]\n",
      "[0.00,\t 1.42]\n",
      "[0.00,\t 1.33]\n",
      "[0.00,\t 0.67]\n",
      "[0.00,\t 0.00]\n",
      "[0.00,\t 1.38]\n",
      "[0.00,\t 1.93]\n",
      "------------\n",
      "-- 2 --\n",
      "[0.00,\t 0.12]\n",
      "[0.00,\t 0.01]\n",
      "[0.00,\t 0.01]\n",
      "[0.00,\t 0.29]\n",
      "[0.00,\t 0.51]\n",
      "[0.00,\t 0.55]\n",
      "[0.00,\t 0.02]\n",
      "[0.00,\t 0.00]\n",
      "[0.05,\t 0.66]\n",
      "[0.05,\t 0.83]\n",
      "------------\n",
      "[0.00,\t 322.46]\n",
      "[0.00,\t 530.50]\n",
      "[0.00,\t 553.17]\n",
      "[0.00,\t 554.91]\n",
      "[0.00,\t 446.17]\n",
      "[0.00,\t 472.72]\n",
      "[0.00,\t 501.70]\n",
      "[0.00,\t 655.83]\n",
      "[0.00,\t 590.90]\n",
      "[0.00,\t 580.33]\n",
      "-- 3 --\n",
      "[0.00,\t 2.65]\n",
      "[0.00,\t 0.86]\n",
      "[0.00,\t 2.13]\n",
      "[0.00,\t 0.30]\n",
      "[0.00,\t 0.00]\n",
      "[0.00,\t 0.97]\n",
      "[0.00,\t 0.95]\n",
      "[0.00,\t 0.00]\n",
      "[0.00,\t 0.92]\n",
      "[0.00,\t 1.30]\n",
      "------------\n",
      "-- 3 --\n",
      "[0.17,\t 1.76]\n",
      "[0.00,\t 0.08]\n",
      "[0.00,\t 1.25]\n",
      "[0.00,\t 0.02]\n",
      "[0.00,\t 0.00]\n",
      "[0.00,\t 0.20]\n",
      "[0.00,\t 0.19]\n",
      "[0.00,\t 0.00]\n",
      "[0.00,\t 0.15]\n",
      "[0.00,\t 0.69]\n",
      "------------\n",
      "[0.00,\t 124.01]\n",
      "[0.00,\t 203.66]\n",
      "[0.00,\t 212.34]\n",
      "[0.00,\t 217.01]\n",
      "[0.00,\t 170.93]\n",
      "[0.00,\t 181.93]\n",
      "[0.00,\t 188.07]\n",
      "[0.00,\t 262.42]\n",
      "[0.00,\t 224.31]\n",
      "[0.00,\t 226.56]\n",
      "-- 4 --\n",
      "[0.00,\t 3.14]\n",
      "[0.00,\t 2.07]\n",
      "[0.00,\t 1.93]\n",
      "[0.00,\t 1.45]\n",
      "[0.00,\t 0.96]\n",
      "[0.00,\t 1.29]\n",
      "[0.00,\t 1.74]\n",
      "[0.00,\t 3.02]\n",
      "[0.00,\t 3.62]\n",
      "[0.00,\t 3.17]\n",
      "------------\n",
      "-- 4 --\n",
      "[0.00,\t 0.99]\n",
      "[0.00,\t 0.12]\n",
      "[0.00,\t 0.18]\n",
      "[0.00,\t 0.05]\n",
      "[0.00,\t 0.02]\n",
      "[0.00,\t 0.03]\n",
      "[0.00,\t 0.06]\n",
      "[0.00,\t 1.00]\n",
      "[0.00,\t 1.22]\n",
      "[0.00,\t 1.25]\n",
      "------------\n",
      "[0.00,\t 36.38]\n",
      "[0.00,\t 57.64]\n",
      "[0.00,\t 59.98]\n",
      "[0.00,\t 63.92]\n",
      "[0.00,\t 46.51]\n",
      "[0.00,\t 50.65]\n",
      "[0.00,\t 48.37]\n",
      "[0.00,\t 86.93]\n",
      "[0.00,\t 60.60]\n",
      "[0.00,\t 65.56]\n",
      "-- 5 --\n",
      "[0.00,\t 4.05]\n",
      "[0.00,\t 3.86]\n",
      "[0.00,\t 4.10]\n",
      "[0.00,\t 3.98]\n",
      "[0.00,\t 3.45]\n",
      "[0.00,\t 5.81]\n",
      "[0.00,\t 5.49]\n",
      "[0.00,\t 4.04]\n",
      "[0.00,\t 2.49]\n",
      "[0.00,\t 7.49]\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "verf, iobj, relu_bins, layer_k, label = aggressive_analyze(netname, epsilon, specname)\n",
    "print(verf, label, layer_k)\n",
    "print(relu_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netname = 'mnist_nets/mnist_relu_9_200.txt'\n",
    "epsilon = 0.01\n",
    "specname = 'mnist_images/img1.txt'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
